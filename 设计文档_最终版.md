# 文档对话式内容修改系统 - 最终版设计文档

> 综合 v2 的工程化思路、v3 的性能优化、以及额外的查找准确性与逻辑完整性增强
> 
> **设计目标**：性能、准确性、可维护性三者平衡，支持渐进式优化

---

## 版本演进说明

### v1 → v2 改进
- 引入乐观锁并发控制
- 明确状态机回退策略
- 简化分块策略（按自然段）
- 增加预览确认机制

### v2 → v3 改进
- Block Version 模型（稳定 block_id）
- evidence_quote 位置校验
- 批量修改三阶段机制

### 最终版增强
- **混合检索策略**（BM25 + 向量 + 重排）
- **渐进式存储优化**（支持从全量复制平滑升级到引用父版本）
- **智能分块策略**（自适应长度控制）
- **多级缓存架构**（Redis + 本地缓存）
- **完整的错误恢复机制**

---

## 0. 核心设计原则

1. **内容优先，格式次之**：统一存储 Markdown，不追求完美还原 docx 格式
2. **修改可控**：LLM 输出结构化计划，服务端严格执行
3. **可审计可回滚**：每次修改生成新 revision，完整审计链
4. **定位可验证**：evidence_quote + 位置信息双重校验
5. **性能可扩展**：支持从简单方案平滑升级到高性能方案
6. **查找准确性**：混合检索 + 重排 + 用户反馈学习

---

## 1. 数据模型（Postgres）

### 1.1 文档与版本

```sql
-- 文档主表
CREATE TABLE documents (
  doc_id           UUID PRIMARY KEY,
  user_id          UUID NOT NULL,
  title            TEXT NOT NULL,
  source_filename  TEXT,
  source_format    TEXT, -- docx/txt/md/pdf
  
  -- 统计信息（冗余字段，便于查询）
  total_blocks     INT NOT NULL DEFAULT 0,
  total_chars      INT NOT NULL DEFAULT 0,
  
  created_at       TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at       TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_documents_user_created ON documents(user_id, created_at DESC);

-- 版本表
CREATE TABLE document_revisions (
  rev_id        UUID PRIMARY KEY,
  doc_id        UUID NOT NULL REFERENCES documents(doc_id) ON DELETE CASCADE,
  rev_no        BIGINT NOT NULL,
  parent_rev_id UUID REFERENCES document_revisions(rev_id),
  
  created_by    TEXT NOT NULL, -- "user" | "ai" | "system"
  change_summary TEXT,         -- 简短描述（如"修改了 3 处内容"）
  
  created_at    TIMESTAMPTZ NOT NULL DEFAULT now(),

  UNIQUE (doc_id, rev_no)
);

CREATE INDEX idx_revisions_doc_no ON document_revisions(doc_id, rev_no DESC);

-- 当前生效版本（乐观锁）
CREATE TABLE document_active_revision (
  doc_id      UUID PRIMARY KEY REFERENCES documents(doc_id) ON DELETE CASCADE,
  rev_id      UUID NOT NULL REFERENCES document_revisions(rev_id) ON DELETE RESTRICT,
  version     BIGINT NOT NULL DEFAULT 1, -- 乐观锁版本号
  updated_at  TIMESTAMPTZ NOT NULL DEFAULT now()
);
```

**优化思路**：
- `total_blocks`/`total_chars` 冗余字段：避免频繁 COUNT 查询
- `change_summary`：便于版本列表展示
- `rev_no` 索引降序：最新版本优先

### 1.2 Block 身份与版本（v3 优化）

```sql
-- 稳定的块身份（逻辑段落）
CREATE TABLE blocks (
  block_id     UUID PRIMARY KEY,
  doc_id       UUID NOT NULL REFERENCES documents(doc_id) ON DELETE CASCADE,
  
  -- 首次创建信息
  first_rev_id UUID NOT NULL REFERENCES document_revisions(rev_id),
  created_at   TIMESTAMPTZ NOT NULL DEFAULT now(),
  
  -- 软删除标记（某个 revision 中被删除后标记）
  deleted_at   TIMESTAMPTZ,
  deleted_in_rev_id UUID REFERENCES document_revisions(rev_id)
);

CREATE INDEX idx_blocks_doc ON blocks(doc_id) WHERE deleted_at IS NULL;

-- 块的版本快照（每个 revision 中的具体内容）
CREATE TABLE block_versions (
  block_version_id UUID PRIMARY KEY,
  block_id         UUID NOT NULL REFERENCES blocks(block_id) ON DELETE CASCADE,
  rev_id           UUID NOT NULL REFERENCES document_revisions(rev_id) ON DELETE CASCADE,

  order_index      BIGINT NOT NULL, -- 在文档中的顺序
  block_type       TEXT NOT NULL,   -- heading/paragraph/list/code/table
  heading_level    INT,              -- 1-6，仅 heading 类型有值
  parent_heading_block_id UUID REFERENCES blocks(block_id), -- 指向父级 heading

  -- 内容存储（支持两种模式）
  content_md       TEXT,             -- 直接存储内容（模式 A）
  plain_text       TEXT,             -- 纯文本（用于检索）
  content_hash     TEXT NOT NULL,    -- hash(content_md)
  
  -- 引用父版本（模式 B，性能优化）
  parent_version_id UUID REFERENCES block_versions(block_version_id),
  -- 如果 parent_version_id 不为 NULL，则 content_md/plain_text 为 NULL
  
  created_at       TIMESTAMPTZ NOT NULL DEFAULT now(),

  UNIQUE (block_id, rev_id),
  
  -- 约束：content_md 和 parent_version_id 必须有且只有一个
  CHECK (
    (content_md IS NOT NULL AND parent_version_id IS NULL) OR
    (content_md IS NULL AND parent_version_id IS NOT NULL)
  )
);

CREATE INDEX idx_block_versions_rev_order ON block_versions(rev_id, order_index);
CREATE INDEX idx_block_versions_block ON block_versions(block_id);
CREATE INDEX idx_block_versions_parent ON block_versions(parent_version_id) WHERE parent_version_id IS NOT NULL;
```

**优化思路**：
- **渐进式优化**：初期用模式 A（content_md 直接存储），后期升级到模式 B（引用父版本）
- **软删除**：block 被删除后不物理删除，保留 block_id 用于审计
- **parent_version_id**：未变更的块引用父版本，节省存储空间
- **CHECK 约束**：确保两种模式互斥

### 1.3 编辑操作审计

```sql
CREATE TABLE edit_operations (
  op_id           UUID PRIMARY KEY,
  doc_id          UUID NOT NULL REFERENCES documents(doc_id) ON DELETE CASCADE,
  rev_id          UUID NOT NULL REFERENCES document_revisions(rev_id) ON DELETE CASCADE,
  parent_rev_id   UUID,

  trace_id        TEXT, -- Langfuse trace id
  user_id         UUID NOT NULL,

  op_type         TEXT NOT NULL, -- replace/insert_after/delete/move
  target_block_id UUID REFERENCES blocks(block_id),
  target_blocks   UUID[], -- 批量操作时使用

  -- 证据信息（v3 增强）
  evidence_quote  TEXT NOT NULL,
  quote_start     INT,  -- 在 plain_text 中的起始位置
  quote_end       INT,  -- 在 plain_text 中的结束位置
  
  before_hash     TEXT,
  after_hash      TEXT,

  rationale       TEXT, -- 模型理由
  patch_json      JSONB, -- 结构化 patch

  status          TEXT NOT NULL DEFAULT 'applied', -- applied/rolled_back/failed

  created_at      TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_edit_ops_doc_rev ON edit_operations(doc_id, rev_id);
CREATE INDEX idx_edit_ops_trace ON edit_operations(trace_id) WHERE trace_id IS NOT NULL;
CREATE INDEX idx_edit_ops_block ON edit_operations(target_block_id) WHERE target_block_id IS NOT NULL;
```

**优化思路**：
- `quote_start`/`quote_end`：精确位置信息，支持前端高亮
- `target_blocks` 数组：支持批量操作审计
- 索引优化：按 trace_id 和 block_id 查询审计记录



### 1.4 会话与消息（多轮对话）

```sql
CREATE TABLE chat_sessions (
  session_id   UUID PRIMARY KEY,
  user_id      UUID NOT NULL,
  doc_id       UUID NOT NULL REFERENCES documents(doc_id) ON DELETE CASCADE,
  
  -- 会话状态
  status       TEXT NOT NULL DEFAULT 'active', -- active/archived/expired
  
  created_at   TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at   TIMESTAMPTZ NOT NULL DEFAULT now(),
  expires_at   TIMESTAMPTZ -- 会话过期时间（可选）
);

CREATE INDEX idx_chat_sessions_user_doc ON chat_sessions(user_id, doc_id);
CREATE INDEX idx_chat_sessions_status ON chat_sessions(status, updated_at);

CREATE TABLE chat_messages (
  msg_id       UUID PRIMARY KEY,
  session_id   UUID NOT NULL REFERENCES chat_sessions(session_id) ON DELETE CASCADE,
  role         TEXT NOT NULL, -- user/assistant/system
  content      TEXT NOT NULL,
  
  -- 上下文信息（支持多轮对话）
  meta         JSONB, -- {
                      --   "last_edited_block_ids": ["uuid1", "uuid2"],
                      --   "last_rev_id": "uuid",
                      --   "operation_type": "replace",
                      --   "affected_count": 1
                      -- }
  
  created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_chat_messages_session_time ON chat_messages(session_id, created_at);
CREATE INDEX idx_chat_messages_meta_gin ON chat_messages USING gin(meta);
```

**优化思路**：
- `status` 字段：支持会话归档和清理
- `expires_at`：自动清理过期会话
- GIN 索引：支持 JSONB meta 字段的高效查询

### 1.5 用户反馈与学习（新增）

```sql
-- 用户对定位结果的反馈
CREATE TABLE user_feedback (
  feedback_id     UUID PRIMARY KEY,
  doc_id          UUID NOT NULL REFERENCES documents(doc_id) ON DELETE CASCADE,
  session_id      UUID REFERENCES chat_sessions(session_id) ON DELETE SET NULL,
  
  query           TEXT NOT NULL,        -- 用户原始查询
  selected_block_id UUID NOT NULL REFERENCES blocks(block_id),
  rejected_block_ids UUID[],            -- 用户拒绝的候选
  
  feedback_type   TEXT NOT NULL,        -- correct/incorrect/ambiguous
  
  created_at      TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_feedback_doc ON user_feedback(doc_id);
CREATE INDEX idx_feedback_query ON user_feedback USING gin(to_tsvector('simple', query));
```

**优化思路**：
- 收集用户反馈用于改进检索模型
- 可用于训练自定义重排模型
- 支持"相似查询"推荐

---

## 2. Meilisearch 设计（混合检索）

### 2.1 索引结构

**索引名**：`doc_blocks`

**文档结构**：
```json
{
  "id": "{block_id}_{rev_id}",
  "block_id": "uuid",
  "doc_id": "uuid",
  "rev_id": "uuid",
  "rev_no": 12,
  
  "order_index": 120,
  "block_type": "paragraph",
  "heading_level": null,
  "parent_heading_text": "3 项目背景",
  "heading_path": ["1 总则", "1.2 定义"],
  
  "plain_text": "……用于 BM25 检索的纯文本……",
  "content_md": "……用于展示的 Markdown……",
  
  "char_count": 256,
  "created_at": 1737532800
}
```

### 2.2 配置

```json
{
  "filterableAttributes": [
    "doc_id",
    "rev_id",
    "block_type",
    "heading_level",
    "char_count"
  ],
  "sortableAttributes": [
    "order_index",
    "created_at",
    "char_count"
  ],
  "searchableAttributes": [
    "plain_text",
    "parent_heading_text",
    "heading_path"
  ],
  "rankingRules": [
    "words",
    "typo",
    "proximity",
    "attribute",
    "sort",
    "exactness"
  ]
}
```

### 2.3 同步策略

**初次上传**：
```python
def index_document_blocks(doc_id: str, rev_id: str):
    blocks = db.get_block_versions(rev_id)
    docs = [
        {
            "id": f"{block.block_id}_{rev_id}",
            "block_id": str(block.block_id),
            "doc_id": str(doc_id),
            "rev_id": str(rev_id),
            "plain_text": block.plain_text,
            # ...
        }
        for block in blocks
    ]
    meili.index("doc_blocks").add_documents(docs)
```

**增量更新（新 revision）**：
```python
def update_index_for_new_revision(doc_id: str, old_rev_id: str, new_rev_id: str, changed_block_ids: Set[UUID]):
    # 方案 A：全量重新索引（简单，适合小文档）
    if total_blocks < 1000:
        index_document_blocks(doc_id, new_rev_id)
        return
    
    # 方案 B：增量更新（复杂，适合大文档）
    # 1. 索引变更的块
    changed_blocks = db.get_block_versions_by_ids(new_rev_id, changed_block_ids)
    new_docs = [build_meili_doc(block, new_rev_id) for block in changed_blocks]
    meili.index("doc_blocks").add_documents(new_docs)
    
    # 2. 复制未变更块的索引（修改 id 和 rev_id）
    unchanged_block_ids = all_block_ids - changed_block_ids
    for block_id in unchanged_block_ids:
        old_doc = meili.get_document(f"{block_id}_{old_rev_id}")
        new_doc = {
            **old_doc,
            "id": f"{block_id}_{new_rev_id}",
            "rev_id": str(new_rev_id)
        }
        meili.index("doc_blocks").add_documents([new_doc])
```

**优化思路**：
- 小文档（< 1000 blocks）：全量重新索引，实现简单
- 大文档（>= 1000 blocks）：增量更新，性能更好
- 自动选择策略，无需手动配置

---

## 3. 向量检索（可选，提升准确性）

### 3.1 向量存储方案

**方案 A：Postgres + pgvector（推荐）**
```sql
-- 在 block_versions 表增加向量列
ALTER TABLE block_versions ADD COLUMN embedding vector(1536);

-- 创建 HNSW 索引
CREATE INDEX idx_block_versions_embedding 
  ON block_versions 
  USING hnsw (embedding vector_cosine_ops);
```

**方案 B：独立向量数据库（Qdrant/Weaviate）**
- 适合超大规模（百万级 blocks）
- 需要额外维护一个服务

### 3.2 Embedding 生成策略

```python
def generate_embedding(block: BlockVersion) -> List[float]:
    # 使用 OpenAI text-embedding-3-small 或 Qwen embedding
    text = f"{block.parent_heading_text}\n\n{block.plain_text}"
    
    # 截断到 8000 tokens
    text = truncate_text(text, max_tokens=8000)
    
    embedding = embedding_client.embed(text)
    return embedding
```

**优化思路**：
- 包含 heading 上下文：提升语义理解
- 异步生成：上传时同步生成 embedding，不阻塞主流程
- 批量生成：每次最多 100 个 blocks 一起生成，降低 API 调用次数

### 3.3 混合检索策略

```python
def hybrid_search(query: str, doc_id: str, rev_id: str, top_k: int = 20) -> List[Block]:
    # 1. BM25 召回（Meilisearch）
    bm25_results = meili.search(
        query,
        filter=f"doc_id = {doc_id} AND rev_id = {rev_id}",
        limit=top_k
    )
    
    # 2. 向量召回（pgvector）
    query_embedding = embedding_client.embed(query)
    vector_results = db.execute("""
        SELECT block_id, embedding <=> %s::vector AS distance
        FROM block_versions
        WHERE rev_id = %s
        ORDER BY distance
        LIMIT %s
    """, (query_embedding, rev_id, top_k))
    
    # 3. 合并结果（RRF - Reciprocal Rank Fusion）
    combined = reciprocal_rank_fusion(
        [bm25_results, vector_results],
        k=60  # RRF 参数
    )
    
    # 4. 重排（可选，使用 Cohere rerank 或自训练模型）
    if len(combined) > 5:
        reranked = rerank_model.rerank(query, combined, top_n=5)
        return reranked
    
    return combined[:5]
```

**优化思路**：
- BM25 擅长关键词匹配（如"第 3 章"、"交付时间"）
- 向量检索擅长语义理解（如"关于钱的内容" → "付款条款"）
- RRF 融合两者优势
- 重排模型进一步优化排序

---

## 4. 分块策略（智能自适应）

### 4.1 基础规则

```python
class BlockSplitter:
    def __init__(self):
        self.min_block_size = 50    # 最小块大小（字符）
        self.max_block_size = 1000  # 最大块大小（字符）
        self.target_block_size = 300 # 目标块大小（字符）
    
    def split_document(self, markdown: str) -> List[Block]:
        ast = parse_markdown(markdown)
        blocks = []
        heading_stack = []  # 维护 heading 层级栈
        
        for node in ast:
            if node.type == "heading":
                # Heading 单独成块
                block = self._create_heading_block(node, heading_stack)
                blocks.append(block)
                
                # 更新 heading 栈
                self._update_heading_stack(heading_stack, node.level, block.block_id)
            
            elif node.type == "paragraph":
                # 段落成块（可能需要二次切分）
                para_blocks = self._split_paragraph(node, heading_stack)
                blocks.extend(para_blocks)
            
            elif node.type == "list":
                # 列表整体成块（MVP）
                block = self._create_list_block(node, heading_stack)
                blocks.append(block)
            
            elif node.type in ["code", "table"]:
                # 代码/表格单独成块
                block = self._create_special_block(node, heading_stack)
                blocks.append(block)
        
        # 设置 order_index
        for i, block in enumerate(blocks):
            block.order_index = i
        
        return blocks
    
    def _split_paragraph(self, node, heading_stack) -> List[Block]:
        text = node.text
        
        # 如果段落不超过最大长度，直接成块
        if len(text) <= self.max_block_size:
            return [self._create_paragraph_block(text, heading_stack)]
        
        # 否则按句子切分
        sentences = self._split_sentences(text)
        blocks = []
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_len = len(sentence)
            
            if current_length + sentence_len > self.max_block_size and current_chunk:
                # 当前 chunk 已满，生成块
                blocks.append(self._create_paragraph_block(
                    "".join(current_chunk),
                    heading_stack
                ))
                current_chunk = [sentence]
                current_length = sentence_len
            else:
                current_chunk.append(sentence)
                current_length += sentence_len
        
        # 最后一个 chunk
        if current_chunk:
            blocks.append(self._create_paragraph_block(
                "".join(current_chunk),
                heading_stack
            ))
        
        return blocks
    
    def _split_sentences(self, text: str) -> List[str]:
        # 按中文句号、英文句号、分号、换行切分
        import re
        sentences = re.split(r'([。.;；\n])', text)
        
        # 重新组合（保留分隔符）
        result = []
        for i in range(0, len(sentences) - 1, 2):
            result.append(sentences[i] + sentences[i + 1])
        
        return result
```

**优化思路**：
- **自适应长度**：根据内容类型动态调整块大小
- **保持语义完整**：按句子切分，不破坏语义
- **heading 栈**：维护层级关系，便于定位"在某章节下"

### 4.2 特殊内容处理

```python
def handle_special_content(node):
    if node.type == "table":
        # 表格：如果行数 > 20，按行分组切分
        if node.row_count > 20:
            return split_table_by_rows(node, rows_per_block=10)
        else:
            return [create_table_block(node)]
    
    elif node.type == "code":
        # 代码块：如果行数 > 50，按函数/类切分
        if node.line_count > 50:
            return split_code_by_functions(node)
        else:
            return [create_code_block(node)]
    
    elif node.type == "list":
        # 列表：如果 item 数 > 20，按 10 个 item 一组切分
        if node.item_count > 20:
            return split_list_by_items(node, items_per_block=10)
        else:
            return [create_list_block(node)]
```

**优化思路**：
- 大表格/列表：按行/项切分，避免单个块过大
- 代码块：按函数切分，保持代码逻辑完整
- 可配置：不同文档类型可以有不同的切分策略

---

## 5. LLM 体系设计（LangChain + LangGraph）

### 5.1 节点职责

```python
class EditWorkflow:
    """LangGraph 工作流节点定义"""
    
    # 基础节点
    INTENT_PARSE = "intent_parse"           # 解析用户意图
    RETRIEVE = "retrieve_candidates"        # 召回候选块
    VERIFY_SELECT = "verify_and_select"     # 验证并选择目标块
    PLAN_EDITS = "plan_edits"              # 生成编辑计划
    PREVIEW = "preview_diff"                # 生成预览
    APPLY = "apply_edits"                   # 应用修改
    EXPORT = "export_document"              # 导出文档
    
    # 批量修改节点（v3）
    BULK_DISCOVER = "bulk_discover"         # 批量召回
    BULK_PREVIEW = "bulk_preview"           # 批量预览
    BULK_APPLY = "bulk_apply"               # 批量应用
    
    # 交互节点
    ASK_USER_SELECT = "ask_user_select"     # 请求用户选择候选
    ASK_USER_CONFIRM = "ask_user_confirm"   # 请求用户确认预览
    
    # 错误处理节点
    HANDLE_ERROR = "handle_error"           # 错误处理
    RETRY_LOCATE = "retry_locate"           # 重试定位
```

### 5.2 状态定义

```python
from typing import TypedDict, Optional, List

class EditState(TypedDict):
    # 基础信息
    doc_id: str
    session_id: str
    user_id: str
    active_rev_id: str
    active_rev_no: int
    active_version: int  # 乐观锁版本号
    
    # 用户输入
    user_message: str
    user_selection: Optional[str]  # 用户选择的 block_id
    user_confirmation: Optional[bool]  # 用户确认预览
    
    # 中间结果
    intent: Optional[Intent]
    candidates: List[BlockCandidate]
    selection: Optional[TargetSelection]
    edit_plan: Optional[EditPlan]
    preview_diff: Optional[PreviewDiff]
    confirm_token: Optional[str]
    
    # 最终结果
    apply_result: Optional[ApplyResult]
    export_md: Optional[str]
    
    # 控制字段
    retry_count: int
    max_retries: int
    error: Optional[ErrorInfo]
    need_user_action: Optional[str]  # "select_candidate" | "confirm_preview" | None
    
    # 性能追踪
    start_time: float
    step_timings: Dict[str, float]
```



### 5.3 结构化输出 Schema

#### Intent（意图）

```python
from pydantic import BaseModel, Field
from typing import List, Optional, Literal

class ScopeHint(BaseModel):
    heading: Optional[str] = Field(None, description="章节名称（不带编号）")
    nearby: Optional[str] = Field(None, description="相对位置：'上一段'/'结尾'/'开头'")
    keywords: List[str] = Field(default_factory=list, description="关键词列表")
    block_type: Optional[str] = Field(None, description="块类型过滤：heading/paragraph/list")

class Constraints(BaseModel):
    tone: Literal["formal", "neutral", "casual"] = "neutral"
    keep_length: Literal["shorter", "similar", "longer"] = "similar"
    must_include: List[str] = Field(default_factory=list, description="必须包含的内容")
    must_exclude: List[str] = Field(default_factory=list, description="必须排除的内容")

class Intent(BaseModel):
    operation: Literal["replace", "insert_after", "insert_before", "delete", "multi_replace"]
    scope_hint: ScopeHint
    constraints: Constraints
    risk: Literal["low", "medium", "high"]
    
    # 批量修改相关（v3）
    match_type: Optional[Literal["exact_term", "regex", "semantic"]] = None
    apply_scope: Optional[Literal["single", "all_matches", "within_heading"]] = None
    scope_filter: Optional[dict] = None
```

#### TargetSelection（定位结果）

```python
class BlockCandidate(BaseModel):
    block_id: str
    snippet: str = Field(..., description="候选片段摘要（前 200 字）")
    heading_context: str = Field(..., description="所属章节")
    order_index: int
    score: float = Field(..., description="相关性分数 0-1")

class EvidenceQuote(BaseModel):
    text: str = Field(..., description="证据引用文本（10-50 字）")
    start: int = Field(..., description="在 plain_text 中的起始位置")
    end: int = Field(..., description="在 plain_text 中的结束位置")

class TargetBlock(BaseModel):
    block_id: str
    evidence: EvidenceQuote
    confidence: float = Field(..., ge=0.0, le=1.0)

class TargetSelection(BaseModel):
    targets: List[TargetBlock]
    need_user_disambiguation: bool = False
    candidates_for_user: List[BlockCandidate] = Field(default_factory=list)
    reasoning: str = Field(..., description="选择理由")
```

#### EditPlan（编辑计划）

```python
class EditOperation(BaseModel):
    op_type: Literal["replace", "insert_after", "insert_before", "delete"]
    target_block_id: str
    evidence: EvidenceQuote
    new_content_md: Optional[str] = None  # replace/insert 时必须
    rationale: str = Field(..., max_length=200, description="修改理由")

class EditPlan(BaseModel):
    doc_id: str
    rev_id: str
    operations: List[EditOperation]
    estimated_impact: Literal["low", "medium", "high"]
    requires_confirmation: bool = False
```

#### PreviewDiff（预览）

```python
class DiffItem(BaseModel):
    block_id: str
    op_type: str
    before_snippet: str
    after_snippet: str
    heading_context: str
    char_diff: int  # 字符数变化

class PreviewDiff(BaseModel):
    diffs: List[DiffItem]
    total_changes: int
    estimated_impact: Literal["low", "medium", "high"]
    
    # 批量修改统计（v3）
    grouped_by_heading: Optional[Dict[str, int]] = None
    total_chars_added: int = 0
    total_chars_removed: int = 0
```

### 5.4 状态机流程图

```text
START
  ↓
intent_parse
  ↓
  ├─ (operation == "multi_replace") ──→ BULK_DISCOVER
  │                                       ↓
  │                                     BULK_PREVIEW
  │                                       ↓
  │                                     ASK_USER_CONFIRM
  │                                       ↓
  │                                     BULK_APPLY ──→ export_document → END
  │
  └─ (operation != "multi_replace") ──→ retrieve_candidates
                                          ↓
                                        verify_and_select
                                          ↓
                                          ├─ (need_disambiguation) ──→ ASK_USER_SELECT → END
                                          │
                                          ├─ (confidence < 0.7) ──→ RETRY_LOCATE
                                          │                           ↓
                                          │                         (retry_count >= max_retries) → ASK_USER_SELECT → END
                                          │                           ↓
                                          │                         retrieve_candidates (重试)
                                          │
                                          └─ (confidence >= 0.7) ──→ plan_edits
                                                                      ↓
                                                                    preview_diff
                                                                      ↓
                                                                      ├─ (estimated_impact == "high") ──→ ASK_USER_CONFIRM → END
                                                                      │
                                                                      └─ (estimated_impact <= "medium") ──→ apply_edits
                                                                                                              ↓
                                                                                                              ├─ (validation_failed) ──→ RETRY_LOCATE
                                                                                                              │
                                                                                                              ├─ (cas_conflict) ──→ HANDLE_ERROR
                                                                                                              │                       ↓
                                                                                                              │                     (retry_count < max_retries) → retrieve_candidates
                                                                                                              │                       ↓
                                                                                                              │                     (retry_count >= max_retries) → END (error)
                                                                                                              │
                                                                                                              └─ (success) ──→ export_document → END
```

### 5.5 关键节点实现

#### 5.5.1 IntentParser（意图解析）

```python
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser

class IntentParserNode:
    def __init__(self, llm):
        self.llm = llm
        self.parser = PydanticOutputParser(pydantic_object=Intent)
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """你是一个文档编辑意图解析助手。
            
规则：
1. 不要直接生成修改后的内容，只解析意图
2. 必须给出 scope_hint（heading/keywords/nearby）以辅助检索
3. 评估风险等级：
   - delete 操作 → high
   - multi_replace（全文统一替换）→ medium
   - 单段 replace → low
4. 如果用户提到"所有"、"全部"、"统一"，设置 operation = "multi_replace"

{format_instructions}
"""),
            ("user", """用户消息：{user_message}

最近对话上下文：
{recent_context}

输出 JSON：""")
        ])
    
    def __call__(self, state: EditState) -> EditState:
        # 获取最近对话上下文
        recent_messages = get_recent_messages(state["session_id"], limit=6)
        recent_context = format_messages(recent_messages)
        
        # 调用 LLM
        chain = self.prompt | self.llm | self.parser
        intent = chain.invoke({
            "user_message": state["user_message"],
            "recent_context": recent_context,
            "format_instructions": self.parser.get_format_instructions()
        })
        
        state["intent"] = intent
        return state
```

#### 5.5.2 Retriever（混合检索）

```python
class RetrieverNode:
    def __init__(self, meili_client, db, embedding_client=None):
        self.meili = meili_client
        self.db = db
        self.embedding_client = embedding_client
    
    def __call__(self, state: EditState) -> EditState:
        intent = state["intent"]
        doc_id = state["doc_id"]
        rev_id = state["active_rev_id"]
        
        # 构建查询
        query = self._build_query(intent)
        
        # 混合检索
        if self.embedding_client:
            candidates = self._hybrid_search(query, doc_id, rev_id, top_k=20)
        else:
            candidates = self._bm25_search(query, doc_id, rev_id, top_k=20)
        
        # 过滤（根据 scope_hint）
        filtered = self._filter_by_scope(candidates, intent.scope_hint)
        
        state["candidates"] = filtered[:10]  # 返回 Top-10
        return state
    
    def _build_query(self, intent: Intent) -> str:
        parts = []
        
        if intent.scope_hint.heading:
            parts.append(intent.scope_hint.heading)
        
        if intent.scope_hint.keywords:
            parts.extend(intent.scope_hint.keywords)
        
        return " ".join(parts)
    
    def _hybrid_search(self, query: str, doc_id: str, rev_id: str, top_k: int) -> List[BlockCandidate]:
        # BM25 召回
        bm25_results = self.meili.index("doc_blocks").search(
            query,
            filter=f"doc_id = {doc_id} AND rev_id = {rev_id}",
            limit=top_k
        )
        
        # 向量召回
        query_embedding = self.embedding_client.embed(query)
        vector_results = self.db.execute("""
            SELECT bv.block_id, bv.plain_text, bv.order_index,
                   b.parent_heading_text,
                   bv.embedding <=> %s::vector AS distance
            FROM block_versions bv
            JOIN blocks b ON bv.block_id = b.block_id
            WHERE bv.rev_id = %s
            ORDER BY distance
            LIMIT %s
        """, (query_embedding, rev_id, top_k))
        
        # RRF 融合
        combined = reciprocal_rank_fusion(
            [bm25_results, vector_results],
            k=60
        )
        
        return combined
    
    def _filter_by_scope(self, candidates: List[BlockCandidate], scope: ScopeHint) -> List[BlockCandidate]:
        filtered = candidates
        
        # 按 block_type 过滤
        if scope.block_type:
            filtered = [c for c in filtered if c.block_type == scope.block_type]
        
        # 按 heading 过滤
        if scope.heading:
            filtered = [c for c in filtered if scope.heading in c.heading_context]
        
        return filtered
```

#### 5.5.3 Verifier/Selector（定位验证）

```python
class VerifierNode:
    def __init__(self, llm):
        self.llm = llm
        self.parser = PydanticOutputParser(pydantic_object=TargetSelection)
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """你是一个文档定位助手。

关键规则：
1. evidence_quote 必须从候选段落的 snippet 中"逐字截取"（10~50 字）
2. 必须给出 start 和 end 位置（在 snippet 中的字符索引）
3. 如果有多个候选都很相似，设置 need_user_disambiguation=true
4. confidence < 0.7 时，必须返回候选列表让用户选择

{format_instructions}
"""),
            ("user", """用户意图：
{intent}

候选段落：
{candidates}

输出 JSON：""")
        ])
    
    def __call__(self, state: EditState) -> EditState:
        # 如果用户已经选择了候选，直接使用
        if state.get("user_selection"):
            selected_block = find_block(state["candidates"], state["user_selection"])
            state["selection"] = TargetSelection(
                targets=[TargetBlock(
                    block_id=selected_block.block_id,
                    evidence=self._extract_evidence(selected_block),
                    confidence=1.0
                )],
                need_user_disambiguation=False,
                reasoning="用户手动选择"
            )
            return state
        
        # 调用 LLM 选择
        chain = self.prompt | self.llm | self.parser
        selection = chain.invoke({
            "intent": state["intent"].model_dump_json(),
            "candidates": format_candidates(state["candidates"]),
            "format_instructions": self.parser.get_format_instructions()
        })
        
        # 服务端校验 evidence_quote
        for target in selection.targets:
            block = find_block(state["candidates"], target.block_id)
            if not self._verify_evidence(block.plain_text, target.evidence):
                # 校验失败，降低 confidence
                target.confidence *= 0.5
        
        state["selection"] = selection
        return state
    
    def _verify_evidence(self, plain_text: str, evidence: EvidenceQuote) -> bool:
        # 方法 1：精确位置校验
        extracted = plain_text[evidence.start:evidence.end]
        if normalize(extracted) == normalize(evidence.text):
            return True
        
        # 方法 2：子串匹配
        if normalize(evidence.text) in normalize(plain_text):
            return True
        
        # 方法 3：滑窗模糊匹配
        return sliding_window_match(plain_text, evidence.text, threshold=0.85)
```

#### 5.5.4 EditPlanner（编辑计划）

```python
class EditPlannerNode:
    def __init__(self, llm):
        self.llm = llm
        self.parser = PydanticOutputParser(pydantic_object=EditPlan)
        
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """你是一个文档编辑计划生成助手。

关键规则：
1. 只修改目标块，不得引入无关段落
2. 严格遵守 constraints（tone, keep_length, must_include）
3. rationale 简短说明修改理由（< 200 字）
4. evidence_quote 原样透传（从 Verifier 输出中获取）
5. 对于 replace 操作，new_content_md 必须保持原有的 Markdown 格式
6. 如果是 delete 操作，设置 requires_confirmation=true

{format_instructions}
"""),
            ("user", """用户意图：
{intent}

目标块内容：
{target_block_content}

evidence_quote：{evidence_quote}

输出 JSON：""")
        ])
    
    def __call__(self, state: EditState) -> EditState:
        selection = state["selection"]
        intent = state["intent"]
        
        # 获取目标块完整内容
        target_blocks = []
        for target in selection.targets:
            block = self.db.get_block_version(target.block_id, state["active_rev_id"])
            target_blocks.append(block)
        
        # 生成编辑计划
        operations = []
        for target, block in zip(selection.targets, target_blocks):
            chain = self.prompt | self.llm | self.parser
            plan = chain.invoke({
                "intent": intent.model_dump_json(),
                "target_block_content": block.content_md,
                "evidence_quote": target.evidence.text,
                "format_instructions": self.parser.get_format_instructions()
            })
            operations.extend(plan.operations)
        
        edit_plan = EditPlan(
            doc_id=state["doc_id"],
            rev_id=state["active_rev_id"],
            operations=operations,
            estimated_impact=self._estimate_impact(operations),
            requires_confirmation=self._needs_confirmation(operations)
        )
        
        state["edit_plan"] = edit_plan
        return state
    
    def _estimate_impact(self, operations: List[EditOperation]) -> str:
        if any(op.op_type == "delete" for op in operations):
            return "high"
        if len(operations) > 3:
            return "medium"
        return "low"
    
    def _needs_confirmation(self, operations: List[EditOperation]) -> bool:
        return any(op.op_type in ["delete", "move"] for op in operations)
```



#### 5.5.5 PreviewGenerator（预览生成）

```python
class PreviewGeneratorNode:
    def __init__(self, db, redis_client):
        self.db = db
        self.redis = redis_client
    
    def __call__(self, state: EditState) -> EditState:
        edit_plan = state["edit_plan"]
        
        # 获取目标块
        blocks = self.db.get_block_versions_by_ids(
            state["active_rev_id"],
            [op.target_block_id for op in edit_plan.operations]
        )
        
        # 生成 diff
        diffs = []
        total_chars_added = 0
        total_chars_removed = 0
        
        for op in edit_plan.operations:
            block = find_block(blocks, op.target_block_id)
            
            before_snippet = block.plain_text[:200]
            
            if op.op_type == "replace":
                after_snippet = strip_markdown(op.new_content_md)[:200]
                char_diff = len(op.new_content_md) - len(block.content_md)
            elif op.op_type == "delete":
                after_snippet = "[已删除]"
                char_diff = -len(block.content_md)
            elif op.op_type in ["insert_after", "insert_before"]:
                after_snippet = f"{before_snippet}\n\n[新增] {strip_markdown(op.new_content_md)[:100]}"
                char_diff = len(op.new_content_md)
            
            if char_diff > 0:
                total_chars_added += char_diff
            else:
                total_chars_removed += abs(char_diff)
            
            diffs.append(DiffItem(
                block_id=op.target_block_id,
                op_type=op.op_type,
                before_snippet=before_snippet,
                after_snippet=after_snippet,
                heading_context=block.parent_heading_text or "（无标题）",
                char_diff=char_diff
            ))
        
        # 按章节分组统计
        grouped = {}
        for diff in diffs:
            heading = diff.heading_context
            grouped[heading] = grouped.get(heading, 0) + 1
        
        preview = PreviewDiff(
            diffs=diffs,
            total_changes=len(diffs),
            estimated_impact=edit_plan.estimated_impact,
            grouped_by_heading=grouped,
            total_chars_added=total_chars_added,
            total_chars_removed=total_chars_removed
        )
        
        # 计算 preview_hash（用于前端回传校验）
        import hashlib
        import json
        preview_json = json.dumps(preview.model_dump(), sort_keys=True)
        preview_hash = hashlib.sha256(preview_json.encode()).hexdigest()
        
        # 生成 confirm_token（如果需要确认）
        if edit_plan.requires_confirmation or edit_plan.estimated_impact == "high":
            token = self._generate_confirm_token(state, edit_plan, preview)
            state["confirm_token"] = token
            state["preview_hash"] = preview_hash  # 前端需要回传
            state["need_user_action"] = "confirm_preview"
        
        state["preview_diff"] = preview
        return state
    
    def _generate_confirm_token(self, state: EditState, edit_plan: EditPlan, preview: PreviewDiff) -> str:
        import hashlib
        import json
        from uuid import uuid4
        
        token_id = str(uuid4())
        
        # 计算 preview_hash
        preview_json = json.dumps(preview.model_dump(), sort_keys=True)
        preview_hash = hashlib.sha256(preview_json.encode()).hexdigest()
        
        # 计算 edit_plan_hash（额外保护）
        plan_json = json.dumps(edit_plan.model_dump(), sort_keys=True)
        plan_hash = hashlib.sha256(plan_json.encode()).hexdigest()
        
        payload = {
            "token_id": token_id,
            "session_id": state["session_id"],
            "doc_id": state["doc_id"],
            "active_rev_id": state["active_rev_id"],
            "active_version": state["active_version"],  # 关键：乐观锁版本号
            "preview_hash": preview_hash,
            "plan_hash": plan_hash,
            "edit_plan": edit_plan.model_dump(),
            "created_at": time.time(),
            "expires_at": time.time() + 900  # 15 分钟
        }
        
        # 存储到 Redis（15 分钟过期）
        self.redis.setex(
            f"confirm_token:{state['session_id']}:{token_id}",
            900,  # 15 分钟
            json.dumps(payload)
        )
        
        return token_id

**安全说明**：
- `preview_hash`：确保用户确认的预览内容与实际执行的内容一致，防止 token 被复用到不同的预览
- `plan_hash`：防止 Redis 中的 payload 被篡改，确保 edit_plan 的完整性
- `active_version`：防止并发修改导致的版本冲突
- 三重校验（preview + plan + version）确保"所见即所得"的修改安全性
```

#### 5.5.6 ApplyEdits（应用修改）

```python
class ApplyEditsNode:
    def __init__(self, db, meili_client):
        self.db = db
        self.meili = meili_client
    
    def __call__(self, state: EditState) -> EditState:
        edit_plan = state["edit_plan"]
        doc_id = state["doc_id"]
        active_rev_id = state["active_rev_id"]
        active_version = state["active_version"]
        
        try:
            with self.db.transaction():
                # 1. 读取当前 revision 的所有 block_versions
                current_blocks = self.db.get_block_versions(active_rev_id)
                
                # 2. 校验所有 operations
                for op in edit_plan.operations:
                    self._validate_operation(current_blocks, op)
                
                # 3. 执行变更（生成新 block_versions）
                new_blocks, changed_block_ids = self._apply_operations(
                    current_blocks,
                    edit_plan.operations
                )
                
                # 4. 创建新 revision
                new_rev = self.db.create_revision(
                    doc_id=doc_id,
                    rev_no=self._get_next_rev_no(doc_id),
                    parent_rev_id=active_rev_id,
                    created_by="ai",
                    change_summary=self._generate_summary(edit_plan.operations)
                )
                
                # 5. 插入新 block_versions
                self.db.insert_block_versions(new_blocks, new_rev.rev_id)
                
                # 6. 写入 edit_operations（审计）
                for op in edit_plan.operations:
                    self.db.insert_edit_operation(
                        op=op,
                        rev_id=new_rev.rev_id,
                        parent_rev_id=active_rev_id,
                        trace_id=state.get("trace_id")
                    )
                
                # 7. 更新 active_rev（CAS 操作）
                updated = self.db.execute("""
                    UPDATE document_active_revision
                    SET rev_id = %s, version = version + 1, updated_at = now()
                    WHERE doc_id = %s AND version = %s
                    RETURNING version
                """, (new_rev.rev_id, doc_id, active_version))
                
                if not updated:
                    raise ConcurrentEditError("version_mismatch")
                
                new_version = updated[0]["version"]
                
                # 8. 更新 Meilisearch 索引
                self._update_search_index(
                    doc_id,
                    active_rev_id,
                    new_rev.rev_id,
                    changed_block_ids,
                    new_blocks
                )
                
                state["apply_result"] = ApplyResult(
                    new_rev_id=new_rev.rev_id,
                    new_rev_no=new_rev.rev_no,
                    new_version=new_version,
                    op_ids=[op.op_id for op in edit_plan.operations]
                )
                
                return state
        
        except ValidationError as e:
            state["error"] = ErrorInfo(code="validation_failed", message=str(e))
            state["retry_count"] += 1
            return state
        
        except ConcurrentEditError as e:
            state["error"] = ErrorInfo(code="concurrent_edit", message=str(e))
            state["retry_count"] += 1
            
            # 刷新 active_rev
            active_rev = self.db.get_active_revision(doc_id)
            state["active_rev_id"] = active_rev.rev_id
            state["active_version"] = active_rev.version
            
            return state
    
    def _validate_operation(self, blocks: List[BlockVersion], op: EditOperation):
        # 1. 目标块存在性
        target_block = find_block(blocks, op.target_block_id)
        if not target_block:
            raise ValidationError(f"target_block_not_found: {op.target_block_id}")
        
        # 2. evidence_quote 校验
        if not self._verify_evidence(target_block.plain_text, op.evidence):
            raise ValidationError(f"evidence_quote_not_matched: {op.evidence.text}")
        
        # 3. content_hash 校验（可选但推荐）
        # if target_block.content_hash != op.before_hash:
        #     raise ValidationError("content_hash_mismatch")
    
    def _verify_evidence(self, plain_text: str, evidence: EvidenceQuote) -> bool:
        # 精确位置校验
        extracted = plain_text[evidence.start:evidence.end]
        if normalize(extracted) == normalize(evidence.text):
            return True
        
        # 子串匹配（兜底）
        return normalize(evidence.text) in normalize(plain_text)
    
    def _apply_operations(self, current_blocks: List[BlockVersion], operations: List[EditOperation]) -> Tuple[List[BlockVersion], Set[UUID]]:
        """
        应用编辑操作，返回新的 block_versions 和变更的 block_ids
        
        支持两种模式：
        - 模式 A：全量复制（content_md 直接存储）
        - 模式 B：引用父版本（parent_version_id 指向旧版本）
        """
        # 按 order_index 排序
        sorted_blocks = sorted(current_blocks, key=lambda b: b.order_index)
        
        new_blocks = []
        changed_block_ids = set()
        
        # 构建操作映射
        op_map = {op.target_block_id: op for op in operations}
        
        for block in sorted_blocks:
            op = op_map.get(str(block.block_id))
            
            if op:
                # 有操作：生成新 block_version
                changed_block_ids.add(block.block_id)
                
                if op.op_type == "replace":
                    new_block = BlockVersion(
                        block_version_id=uuid4(),
                        block_id=block.block_id,
                        rev_id=None,  # 稍后设置
                        order_index=0,  # 临时值，稍后统一重排
                        block_type=block.block_type,
                        heading_level=block.heading_level,
                        parent_heading_block_id=block.parent_heading_block_id,
                        content_md=op.new_content_md,
                        plain_text=strip_markdown(op.new_content_md),
                        content_hash=hash_content(op.new_content_md),
                        parent_version_id=None  # 模式 A
                    )
                    new_blocks.append(new_block)
                
                elif op.op_type == "delete":
                    # 1. 标记 blocks 表的软删除
                    self.db.execute("""
                        UPDATE blocks
                        SET deleted_at = now(),
                            deleted_in_rev_id = %s
                        WHERE block_id = %s
                    """, (self.new_rev_id, block.block_id))
                    
                    # 2. 不添加到 new_blocks（该 revision 中不存在该块）
                    continue
                
                elif op.op_type == "insert_after":
                    # 先添加原块
                    new_blocks.append(self._copy_block_version(block))
                    
                    # 创建新块（先创建 blocks 记录）
                    new_block = self._create_inserted_block(op, self.doc_id, self.new_rev_id)
                    new_blocks.append(new_block)
                    changed_block_ids.add(new_block.block_id)
                
                elif op.op_type == "insert_before":
                    # 先添加新块
                    new_block = self._create_inserted_block(op, self.doc_id, self.new_rev_id)
                    new_blocks.append(new_block)
                    changed_block_ids.add(new_block.block_id)
                    
                    # 再添加原块
                    new_blocks.append(self._copy_block_version(block))
            
            else:
                # 无操作：复用（模式 A）或引用（模式 B）
                # 模式 A：全量复制
                new_blocks.append(self._copy_block_version(block))
                
                # 模式 B：引用父版本（性能优化）
                # new_blocks.append(BlockVersion(
                #     block_version_id=uuid4(),
                #     block_id=block.block_id,
                #     rev_id=None,
                #     order_index=0,
                #     block_type=block.block_type,
                #     heading_level=block.heading_level,
                #     parent_heading_block_id=block.parent_heading_block_id,
                #     content_md=None,
                #     plain_text=None,
                #     content_hash=block.content_hash,
                #     parent_version_id=block.block_version_id  # 引用父版本
                # ))
        
        # 统一重排 order_index（确保连续的 BIGINT，留出间隔）
        for i, block in enumerate(new_blocks):
            block.order_index = i * 10  # 留出间隔，便于后续插入
        
        return new_blocks, changed_block_ids
    
    def _create_inserted_block(self, op: EditOperation, doc_id: str, new_rev_id: str) -> BlockVersion:
        """创建插入的新块（完整版）"""
        new_block_id = uuid4()
        
        # 1. 先在 blocks 表创建稳定身份
        self.db.execute("""
            INSERT INTO blocks (block_id, doc_id, first_rev_id, created_at)
            VALUES (%s, %s, %s, now())
        """, (new_block_id, doc_id, new_rev_id))
        
        # 2. 创建 block_version
        return BlockVersion(
            block_version_id=uuid4(),
            block_id=new_block_id,
            rev_id=None,  # 稍后设置
            order_index=0,  # 临时值，稍后统一重排
            block_type="paragraph",
            heading_level=None,
            parent_heading_block_id=None,  # 可以从上下文推断
            content_md=op.new_content_md,
            plain_text=strip_markdown(op.new_content_md),
            content_hash=hash_content(op.new_content_md),
            parent_version_id=None
        )
    
    def _copy_block_version(self, block: BlockVersion) -> BlockVersion:
        """全量复制 block_version（模式 A）"""
        return BlockVersion(
            block_version_id=uuid4(),
            block_id=block.block_id,
            rev_id=None,
            order_index=0,  # 临时值，稍后统一重排
            block_type=block.block_type,
            heading_level=block.heading_level,
            parent_heading_block_id=block.parent_heading_block_id,
            content_md=block.content_md,
            plain_text=block.plain_text,
            content_hash=block.content_hash,
            parent_version_id=None
        )
    
    def _update_search_index(self, doc_id: str, old_rev_id: str, new_rev_id: str, changed_block_ids: Set[UUID], new_blocks: List[BlockVersion]):
        """
        更新 Meilisearch 索引
        
        策略：只维护当前 active_revision 的索引
        - 删除旧索引（按 doc_id 过滤）
        - 索引新 revision 的所有 blocks
        
        优点：
        - 成本 O(N)，但只在切换 active_revision 时执行
        - 实现简单
        - 符合"只检索当前版本"的需求
        """
        # 1. 删除旧索引（按 doc_id 过滤）
        self.meili.index("doc_blocks").delete_documents({
            "filter": f"doc_id = {doc_id}"
        })
        
        # 2. 索引新 revision 的所有 blocks
        docs = [
            {
                "id": f"{block.block_id}_{new_rev_id}",
                "block_id": str(block.block_id),
                "doc_id": str(doc_id),
                "rev_id": str(new_rev_id),
                "plain_text": block.plain_text,
                "order_index": block.order_index,
                "block_type": block.block_type,
                # ...
            }
            for block in new_blocks
        ]
        
        # 3. 批量索引
        self.meili.index("doc_blocks").add_documents(docs)


---

## 6. 批量修改机制（v3）

### 6.1 BULK_DISCOVER 节点

```python
class BulkDiscoverNode:
    def __init__(self, meili_client, db):
        self.meili = meili_client
        self.db = db
    
    def __call__(self, state: EditState) -> EditState:
        intent = state["intent"]
        doc_id = state["doc_id"]
        rev_id = state["active_rev_id"]
        
        # 构建查询
        if intent.match_type == "exact_term":
            query = intent.scope_filter.get("term", "")
        elif intent.match_type == "regex":
            # Meilisearch 不支持 regex，需要全量拉取后过滤
            query = ""
        else:
            query = " ".join(intent.scope_hint.keywords)
        
        # 分页召回所有匹配的块
        all_candidates = []
        offset = 0
        limit = 100
        
        while True:
            results = self.meili.index("doc_blocks").search(
                query,
                filter=f"doc_id = {doc_id} AND rev_id = {rev_id}",
                limit=limit,
                offset=offset
            )
            
            if not results["hits"]:
                break
            
            all_candidates.extend(results["hits"])
            offset += limit
            
            # 安全限制：最多 1000 个候选
            if len(all_candidates) >= 1000:
                break
        
        # 按 scope_filter 进一步过滤
        filtered = self._filter_by_scope(all_candidates, intent)
        
        # 限制最大影响范围
        MAX_BULK_CHANGES = 100
        if len(filtered) > MAX_BULK_CHANGES:
            state["error"] = ErrorInfo(
                code="too_many_changes",
                message=f"将影响 {len(filtered)} 处，超过限制 {MAX_BULK_CHANGES}，请缩小范围"
            )
            return state
        
        state["candidates"] = filtered
        return state
    
    def _filter_by_scope(self, candidates: List[dict], intent: Intent) -> List[dict]:
        filtered = candidates
        
        # 按 heading 过滤
        if intent.scope_filter and intent.scope_filter.get("heading_ids"):
            heading_ids = set(intent.scope_filter["heading_ids"])
            filtered = [c for c in filtered if c.get("parent_heading_block_id") in heading_ids]
        
        # 按 regex 过滤
        if intent.match_type == "regex":
            import re
            pattern = re.compile(intent.scope_filter.get("pattern", ""))
            filtered = [c for c in filtered if pattern.search(c["plain_text"])]
        
        return filtered
```

### 6.2 BULK_PREVIEW 节点

```python
class BulkPreviewNode:
    def __init__(self, db, redis_client):
        self.db = db
        self.redis = redis_client
    
    def __call__(self, state: EditState) -> EditState:
        intent = state["intent"]
        candidates = state["candidates"]
        
        # 为每个候选生成 diff
        diffs = []
        grouped = {}
        
        for candidate in candidates:
            block = self.db.get_block_version(candidate["block_id"], state["active_rev_id"])
            
            # 生成替换后的内容
            if intent.match_type == "exact_term":
                term = intent.scope_filter["term"]
                replacement = intent.scope_filter["replacement"]
                new_content = block.content_md.replace(term, replacement)
            else:
                # 其他类型需要调用 LLM 生成
                new_content = self._generate_replacement(block, intent)
            
            before_snippet = block.plain_text[:200]
            after_snippet = strip_markdown(new_content)[:200]
            
            diffs.append(DiffItem(
                block_id=block.block_id,
                op_type="replace",
                before_snippet=before_snippet,
                after_snippet=after_snippet,
                heading_context=block.parent_heading_text or "（无标题）",
                char_diff=len(new_content) - len(block.content_md)
            ))
            
            # 按章节分组
            heading = block.parent_heading_text or "（无标题）"
            grouped[heading] = grouped.get(heading, 0) + 1
        
        preview = PreviewDiff(
            diffs=diffs,
            total_changes=len(diffs),
            estimated_impact="medium" if len(diffs) > 10 else "low",
            grouped_by_heading=grouped
        )
        
        # 生成 confirm_token
        token = self._generate_confirm_token(state, preview)
        
        state["preview_diff"] = preview
        state["confirm_token"] = token
        state["need_user_action"] = "confirm_preview"
        
        return state
```

---

## 7. 多级缓存架构

### 7.1 缓存层次

```python
class CacheManager:
    def __init__(self, redis_client, local_cache_size=1000):
        self.redis = redis_client
        self.local_cache = LRUCache(maxsize=local_cache_size)
    
    def get_block_version(self, block_id: str, rev_id: str) -> Optional[BlockVersion]:
        cache_key = f"block:{block_id}:{rev_id}"
        
        # L1: 本地缓存
        if cache_key in self.local_cache:
            return self.local_cache[cache_key]
        
        # L2: Redis 缓存
        cached = self.redis.get(cache_key)
        if cached:
            block = BlockVersion.parse_raw(cached)
            self.local_cache[cache_key] = block
            return block
        
        # L3: 数据库
        block = db.get_block_version(block_id, rev_id)
        if block:
            # 写入缓存（TTL 1 小时）
            self.redis.setex(cache_key, 3600, block.json())
            self.local_cache[cache_key] = block
        
        return block
    
    def invalidate_revision(self, rev_id: str):
        """新 revision 创建后，失效相关缓存"""
        # 删除 Redis 中该 revision 的所有 blocks
        pattern = f"block:*:{rev_id}"
        keys = self.redis.keys(pattern)
        if keys:
            self.redis.delete(*keys)
        
        # 清空本地缓存
        self.local_cache.clear()
```

### 7.2 缓存策略

| 数据类型 | 缓存位置 | TTL | 失效策略 |
|---------|---------|-----|---------|
| block_version | Redis + 本地 | 1 小时 | 新 revision 创建时失效 |
| active_revision | Redis | 5 分钟 | CAS 更新时失效 |
| search_results | Redis | 10 分钟 | 新 revision 创建时失效 |
| confirm_token | Redis | 15 分钟 | 使用后立即删除 |
| user_session | Redis | 24 小时 | 用户登出时删除 |

**优化思路**：
- 本地缓存：减少 Redis 网络开销
- Redis 缓存：跨实例共享，支持分布式部署
- TTL 设置：平衡一致性与性能
- 主动失效：确保数据一致性

---

## 8. API 设计

### 8.1 上传与解析

**POST `/v1/docs/upload`**

```python
@app.post("/v1/docs/upload")
async def upload_document(
    file: UploadFile,
    title: str = Form(...),
    user_id: str = Depends(get_current_user)
):
    # 1. 解析文件
    if file.filename.endswith(".md"):
        markdown = await file.read()
    elif file.filename.endswith(".docx"):
        markdown = convert_docx_to_md(await file.read())
    else:
        raise HTTPException(400, "Unsupported format")
    
    # 2. 分块
    splitter = BlockSplitter()
    blocks = splitter.split_document(markdown.decode())
    
    # 3. 写入数据库
    with db.transaction():
        # 创建文档
        doc = db.create_document(
            user_id=user_id,
            title=title,
            source_filename=file.filename,
            source_format=file.filename.split(".")[-1],
            total_blocks=len(blocks),
            total_chars=sum(len(b.content_md) for b in blocks)
        )
        
        # 创建首个 revision
        rev = db.create_revision(
            doc_id=doc.doc_id,
            rev_no=1,
            created_by="user"
        )
        
        # 创建 blocks 和 block_versions
        for block in blocks:
            db_block = db.create_block(
                block_id=block.block_id,
                doc_id=doc.doc_id,
                first_rev_id=rev.rev_id
            )
            
            db.create_block_version(
                block_id=db_block.block_id,
                rev_id=rev.rev_id,
                order_index=block.order_index,
                block_type=block.block_type,
                content_md=block.content_md,
                plain_text=block.plain_text,
                content_hash=hash_content(block.content_md)
            )
        
        # 设置 active_revision
        db.set_active_revision(doc.doc_id, rev.rev_id)
    
    # 4. 索引到 Meilisearch
    index_document_blocks(doc.doc_id, rev.rev_id)
    
    # 5. 异步生成 embeddings（可选）
    if ENABLE_VECTOR_SEARCH:
        background_tasks.add_task(generate_embeddings, doc.doc_id, rev.rev_id)
    
    return {
        "doc_id": str(doc.doc_id),
        "rev_id": str(rev.rev_id),
        "block_count": len(blocks),
        "title": title
    }
```



### 8.2 对话式编辑

**POST `/v1/chat/edit`**

```python
@app.post("/v1/chat/edit")
async def chat_edit(
    request: ChatEditRequest,
    user_id: str = Depends(get_current_user)
):
    # 初始化状态
    active_rev = db.get_active_revision(request.doc_id)
    
    state = EditState(
        doc_id=request.doc_id,
        session_id=request.session_id,
        user_id=user_id,
        active_rev_id=active_rev.rev_id,
        active_rev_no=active_rev.rev_no,
        active_version=active_rev.version,
        user_message=request.message,
        user_selection=request.user_selection,
        retry_count=0,
        max_retries=2,
        start_time=time.time(),
        step_timings={}
    )
    
    # 运行 LangGraph 工作流
    workflow = build_edit_workflow()
    result = await workflow.ainvoke(state)
    
    # 根据结果返回不同响应
    if result.get("need_user_action") == "select_candidate":
        return ChatEditResponse(
            status="need_disambiguation",
            candidates=[
                CandidateResponse(
                    block_id=c.block_id,
                    snippet=c.snippet,
                    heading_context=c.heading_context,
                    order_index=c.order_index
                )
                for c in result["selection"].candidates_for_user
            ],
            message="找到多个可能的位置，请选择要修改的段落"
        )
    
    elif result.get("need_user_action") == "confirm_preview":
        return ChatEditResponse(
            status="need_confirm",
            preview=result["preview_diff"],
            confirm_token=result["confirm_token"],
            preview_hash=result["preview_hash"],  # 前端需要回传此值
            message="请确认以下修改"
        )
    
    elif result.get("apply_result"):
        return ChatEditResponse(
            status="applied",
            new_rev_id=result["apply_result"].new_rev_id,
            diff_summary=result["preview_diff"].diffs,
            export_md=result["export_md"],
            message=f"已成功修改 {result['preview_diff'].total_changes} 处内容"
        )
    
    else:
        return ChatEditResponse(
            status="failed",
            error=result.get("error"),
            message="修改失败，请重试"
        )
```

### 8.3 确认预览

**POST `/v1/chat/confirm`**

**请求结构**：
```python
class ConfirmRequest(BaseModel):
    session_id: str
    doc_id: str
    confirm_token: str
    action: Literal["apply", "cancel"]
    preview_hash: str  # 必填：前端回传用于二次校验
```

**实现**：
```python
@app.post("/v1/chat/confirm")
async def confirm_edit(
    request: ConfirmRequest,
    user_id: str = Depends(get_current_user)
):
    # 1. 获取 token payload
    token_key = f"confirm_token:{request.session_id}:{request.confirm_token}"
    payload_json = redis.get(token_key)
    
    if not payload_json:
        raise HTTPException(400, "Invalid or expired token")
    
    payload = json.loads(payload_json)
    
    # 2. 基础校验
    if payload["doc_id"] != request.doc_id:
        raise HTTPException(400, "Token doc_id mismatch")
    
    if payload["session_id"] != request.session_id:
        raise HTTPException(400, "Token session_id mismatch")
    
    # 3. 过期校验
    if time.time() > payload["expires_at"]:
        redis.delete(token_key)
        raise HTTPException(400, "Token expired")
    
    # 4. 获取当前 active_revision
    active_rev = db.get_active_revision(request.doc_id)
    
    # 5. 关键校验：active_rev_id 和 active_version 必须完全一致
    if payload["active_rev_id"] != str(active_rev.rev_id):
        redis.delete(token_key)
        raise HTTPException(409, {
            "code": "document_modified",
            "message": "文档已被他人修改，预览已失效",
            "current_rev_id": str(active_rev.rev_id),
            "token_rev_id": payload["active_rev_id"]
        })
    
    if payload["active_version"] != active_rev.version:
        redis.delete(token_key)
        raise HTTPException(409, {
            "code": "version_mismatch",
            "message": "文档版本已变更，预览已失效",
            "current_version": active_rev.version,
            "token_version": payload["active_version"]
        })
    
    # 6. 取消操作（在执行修改前处理）
    if request.action == "cancel":
        redis.delete(token_key)
        return {"status": "cancelled", "message": "已取消修改"}
    
    # 7. 执行修改前的强制校验
    # 7.1 preview_hash 校验（强制）
    if "preview_hash" not in payload:
        redis.delete(token_key)
        raise HTTPException(400, "Token missing preview_hash")
    
    # 前端必须回传 preview_hash 用于二次校验
    if not request.preview_hash:
        redis.delete(token_key)
        raise HTTPException(400, "Request missing preview_hash")
    
    if request.preview_hash != payload["preview_hash"]:
        redis.delete(token_key)
        raise HTTPException(400, {
            "code": "preview_hash_mismatch",
            "message": "预览内容已变更，请重新确认"
        })
    
    # 7.2 plan_hash 校验（强制，防止 payload 被篡改）
    if "plan_hash" not in payload:
        redis.delete(token_key)
        raise HTTPException(400, "Token missing plan_hash")
    
    edit_plan = EditPlan.parse_obj(payload["edit_plan"])
    plan_json = json.dumps(edit_plan.model_dump(), sort_keys=True)
    plan_hash = hashlib.sha256(plan_json.encode()).hexdigest()
    
    if plan_hash != payload["plan_hash"]:
        redis.delete(token_key)
        raise HTTPException(400, {
            "code": "plan_hash_mismatch",
            "message": "编辑计划已被篡改"
        })
    
    # 8. 执行修改
    state = EditState(
        doc_id=request.doc_id,
        session_id=request.session_id,
        user_id=user_id,
        active_rev_id=active_rev.rev_id,
        active_version=active_rev.version,
        edit_plan=edit_plan,
        retry_count=0,
        max_retries=2
    )
    
    # 执行 apply_edits
    apply_node = ApplyEditsNode(db, meili)
    result = apply_node(state)
    
    # 9. 删除 token（一次性使用，无论成功失败）
    redis.delete(token_key)
    
    if result.get("apply_result"):
        export_md = export_document(result["apply_result"].new_rev_id)
        return {
            "status": "applied",
            "new_rev_id": result["apply_result"].new_rev_id,
            "export_md": export_md,
            "message": "修改已应用"
        }
    else:
        return {
            "status": "failed",
            "error": result.get("error"),
            "message": "应用修改失败"
        }
        }
```



### 8.4 导出文档

**GET `/v1/docs/{doc_id}/export`**

```python
@app.get("/v1/docs/{doc_id}/export")
async def export_document(
    doc_id: str,
    rev_id: Optional[str] = None,
    format: str = "md",
    user_id: str = Depends(get_current_user)
):
    # 获取 revision
    if not rev_id:
        active_rev = db.get_active_revision(doc_id)
        rev_id = active_rev.rev_id
    
    # 获取所有 blocks（按 order_index 排序）
    blocks = db.get_block_versions(rev_id, order_by="order_index")
    
    # 拼接 Markdown
    markdown_parts = []
    for block in blocks:
        # 如果是引用父版本（模式 B），需要递归获取内容
        content = block.content_md
        if not content and block.parent_version_id:
            content = get_content_from_parent(block.parent_version_id)
        
        markdown_parts.append(content)
    
    markdown = "\n\n".join(markdown_parts)
    
    if format == "md":
        return Response(
            content=markdown,
            media_type="text/markdown",
            headers={
                "Content-Disposition": f"attachment; filename={doc_id}.md"
            }
        )
    elif format == "docx":
        # 转换为 docx（使用 python-docx 或 pandoc）
        docx_bytes = convert_md_to_docx(markdown)
        return Response(
            content=docx_bytes,
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={
                "Content-Disposition": f"attachment; filename={doc_id}.docx"
            }
        )
    else:
        raise HTTPException(400, "Unsupported format")

def get_content_from_parent(parent_version_id: str) -> str:
    """递归获取父版本的内容（模式 B）"""
    parent = db.get_block_version_by_id(parent_version_id)
    
    if parent.content_md:
        return parent.content_md
    elif parent.parent_version_id:
        return get_content_from_parent(parent.parent_version_id)
    else:
        raise ValueError(f"Cannot find content for block_version {parent_version_id}")
```

### 8.5 版本管理

**GET `/v1/docs/{doc_id}/revisions`**

```python
@app.get("/v1/docs/{doc_id}/revisions")
async def list_revisions(
    doc_id: str,
    limit: int = 20,
    offset: int = 0,
    user_id: str = Depends(get_current_user)
):
    revisions = db.get_revisions(doc_id, limit=limit, offset=offset)
    active_rev = db.get_active_revision(doc_id)
    
    return {
        "revisions": [
            {
                "rev_id": str(rev.rev_id),
                "rev_no": rev.rev_no,
                "created_by": rev.created_by,
                "created_at": rev.created_at.isoformat(),
                "change_summary": rev.change_summary,
                "is_active": rev.rev_id == active_rev.rev_id
            }
            for rev in revisions
        ],
        "total": db.count_revisions(doc_id)
    }
```

**POST `/v1/docs/{doc_id}/rollback`**

```python
@app.post("/v1/docs/{doc_id}/rollback")
async def rollback_revision(
    doc_id: str,
    request: RollbackRequest,
    user_id: str = Depends(get_current_user)
):
    target_rev_id = request.target_rev_id
    
    with db.transaction():
        # 1. 读取目标 revision 的所有 blocks
        target_blocks = db.get_block_versions(target_rev_id)
        
        # 2. 创建新 revision
        current_rev_no = db.get_latest_rev_no(doc_id)
        new_rev = db.create_revision(
            doc_id=doc_id,
            rev_no=current_rev_no + 1,
            parent_rev_id=target_rev_id,
            created_by="system",
            change_summary=f"回滚到版本 {request.target_rev_no}"
        )
        
        # 3. 复制 blocks（模式 A）或引用（模式 B）
        for block in target_blocks:
            db.create_block_version(
                block_id=block.block_id,
                rev_id=new_rev.rev_id,
                order_index=block.order_index,
                block_type=block.block_type,
                content_md=block.content_md,  # 模式 A
                plain_text=block.plain_text,
                content_hash=block.content_hash,
                parent_version_id=None  # 模式 A
                # parent_version_id=block.block_version_id  # 模式 B
            )
        
        # 4. 更新 active_rev
        db.update_active_revision(doc_id, new_rev.rev_id)
        
        # 5. 重新索引
        index_document_blocks(doc_id, new_rev.rev_id)
    
    return {
        "new_rev_id": str(new_rev.rev_id),
        "new_rev_no": new_rev.rev_no,
        "message": f"已回滚到版本 {request.target_rev_no}"
    }
```

---

## 9. Langfuse 观测设计

### 9.1 Trace 结构

```python
from langfuse import Langfuse

langfuse = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST")
)

def create_edit_trace(state: EditState):
    trace = langfuse.trace(
        name="doc_edit",
        user_id=state["user_id"],
        session_id=state["session_id"],
        metadata={
            "doc_id": state["doc_id"],
            "operation_type": state["intent"].operation if state.get("intent") else None,
            "risk_level": state["intent"].risk if state.get("intent") else None
        }
    )
    return trace
```

### 9.2 Span 埋点

```python
class IntentParserNode:
    def __call__(self, state: EditState) -> EditState:
        trace = state.get("langfuse_trace")
        
        with trace.span(name="intent_parse") as span:
            start_time = time.time()
            
            # 调用 LLM
            intent = self.chain.invoke(...)
            
            span.end(
                metadata={
                    "operation": intent.operation,
                    "scope_hint": intent.scope_hint.model_dump(),
                    "risk": intent.risk
                },
                level="DEFAULT",
                status_message="success"
            )
            
            state["step_timings"]["intent_parse"] = time.time() - start_time
            state["intent"] = intent
            
            return state
```

### 9.3 业务指标

```python
def record_edit_metrics(state: EditState, result: dict):
    trace = state.get("langfuse_trace")
    
    # 成功率指标
    trace.score(
        name="validation_passed",
        value=1 if result.get("apply_result") else 0
    )
    
    trace.score(
        name="need_disambiguation",
        value=1 if result.get("need_user_action") == "select_candidate" else 0
    )
    
    # 性能指标
    total_latency = time.time() - state["start_time"]
    trace.score(name="total_latency_ms", value=total_latency * 1000)
    
    # 质量指标
    if result.get("selection"):
        trace.score(
            name="confidence",
            value=result["selection"].targets[0].confidence
        )
    
    # 成本指标（需要从 LLM 响应中提取）
    if result.get("tokens_used"):
        trace.score(name="tokens_in", value=result["tokens_used"]["input"])
        trace.score(name="tokens_out", value=result["tokens_used"]["output"])
```

---

## 10. 性能优化策略

### 10.1 数据库优化

```sql
-- 1. 分区表（大文档场景）
CREATE TABLE block_versions_partitioned (
  LIKE block_versions INCLUDING ALL
) PARTITION BY HASH (doc_id);

CREATE TABLE block_versions_p0 PARTITION OF block_versions_partitioned
  FOR VALUES WITH (MODULUS 4, REMAINDER 0);
-- ... 创建 p1, p2, p3

-- 2. 物化视图（加速导出）
CREATE MATERIALIZED VIEW active_document_content AS
SELECT 
  d.doc_id,
  d.title,
  dar.rev_id,
  array_agg(bv.content_md ORDER BY bv.order_index) AS content_blocks
FROM documents d
JOIN document_active_revision dar ON d.doc_id = dar.doc_id
JOIN block_versions bv ON dar.rev_id = bv.rev_id
GROUP BY d.doc_id, d.title, dar.rev_id;

CREATE UNIQUE INDEX ON active_document_content(doc_id);

-- 定期刷新
REFRESH MATERIALIZED VIEW CONCURRENTLY active_document_content;

-- 3. 连接池配置
-- 使用 pgbouncer 或 SQLAlchemy 连接池
-- pool_size=20, max_overflow=10, pool_timeout=30
```

### 10.2 Meilisearch 优化

```python
# 1. 批量索引
def batch_index_blocks(blocks: List[BlockVersion], batch_size=100):
    for i in range(0, len(blocks), batch_size):
        batch = blocks[i:i+batch_size]
        docs = [build_meili_doc(block) for block in batch]
        meili.index("doc_blocks").add_documents(docs)

# 2. 异步索引
import asyncio

async def async_index_blocks(blocks: List[BlockVersion]):
    tasks = []
    for i in range(0, len(blocks), 100):
        batch = blocks[i:i+100]
        task = asyncio.create_task(index_batch(batch))
        tasks.append(task)
    
    await asyncio.gather(*tasks)

# 3. 索引预热
def warmup_search_index(doc_id: str):
    """预热常见查询"""
    common_queries = ["项目背景", "交付时间", "付款条款", "违约责任"]
    for query in common_queries:
        meili.index("doc_blocks").search(
            query,
            filter=f"doc_id = {doc_id}",
            limit=5
        )
```

### 10.3 向量检索优化

```python
# 1. 批量生成 embeddings
def batch_generate_embeddings(blocks: List[BlockVersion], batch_size=50):
    embeddings = []
    for i in range(0, len(blocks), batch_size):
        batch = blocks[i:i+batch_size]
        texts = [f"{b.parent_heading_text}\n\n{b.plain_text}" for b in batch]
        batch_embeddings = embedding_client.embed_batch(texts)
        embeddings.extend(batch_embeddings)
    
    return embeddings

# 2. 使用 HNSW 索引（pgvector）
CREATE INDEX idx_block_versions_embedding_hnsw
  ON block_versions
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- 查询时设置 ef_search
SET hnsw.ef_search = 40;

# 3. 降维（可选）
# 使用 PCA 或 UMAP 将 1536 维降到 768 维
from sklearn.decomposition import PCA

pca = PCA(n_components=768)
reduced_embeddings = pca.fit_transform(embeddings)
```

---

## 11. 错误处理与恢复

### 11.1 错误分类

```python
class EditError(Exception):
    """编辑错误基类"""
    pass

class ValidationError(EditError):
    """校验失败"""
    pass

class ConcurrentEditError(EditError):
    """并发冲突"""
    pass

class SearchError(EditError):
    """检索失败"""
    pass

class LLMError(EditError):
    """LLM 调用失败"""
    pass
```

### 11.2 重试策略

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class RetryableNode:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((SearchError, LLMError))
    )
    def __call__(self, state: EditState) -> EditState:
        # 节点逻辑
        pass
```

### 11.3 降级策略

```python
def handle_error_with_fallback(state: EditState, error: Exception) -> EditState:
    if isinstance(error, SearchError):
        # 检索失败：降级到简单关键词匹配
        state["candidates"] = simple_keyword_search(state["intent"])
        return state
    
    elif isinstance(error, LLMError):
        # LLM 失败：使用规则引擎
        state["edit_plan"] = rule_based_edit_plan(state["intent"], state["selection"])
        return state
    
    elif isinstance(error, ConcurrentEditError):
        # 并发冲突：刷新后重试
        if state["retry_count"] < state["max_retries"]:
            active_rev = db.get_active_revision(state["doc_id"])
            state["active_rev_id"] = active_rev.rev_id
            state["active_version"] = active_rev.version
            state["retry_count"] += 1
            return state
        else:
            state["error"] = ErrorInfo(
                code="concurrent_edit",
                message="文档已被他人修改，请刷新后重试"
            )
            return state
    
    else:
        # 未知错误：记录日志并返回
        logger.error(f"Unhandled error: {error}", exc_info=True)
        state["error"] = ErrorInfo(
            code="internal_error",
            message="系统错误，请稍后重试"
        )
        return state
```

---

## 12. 安全与权限

### 12.0 confirm_token 安全机制（关键）

**问题**：如果不强制校验 `preview_hash` 和 `plan_hash`，可能出现：
1. Token 被复用到不同的预览（用户看到的是 A，实际执行的是 B）
2. Redis 中的 payload 被篡改（edit_plan 被修改）
3. 并发场景下的"错配修改"

**解决方案**：三重校验机制

```text
生成 token 时：
  ├─ preview_hash = sha256(preview_diff)
  ├─ plan_hash = sha256(edit_plan)
  └─ active_version = 当前乐观锁版本号

确认时强制校验：
  ├─ 1. 基础校验
  │    ├─ doc_id 一致
  │    ├─ session_id 一致
  │    └─ token 未过期
  │
  ├─ 2. 版本校验
  │    ├─ active_rev_id 一致（文档未被修改）
  │    └─ active_version 一致（乐观锁版本号）
  │
  ├─ 3. 内容校验（强制）
  │    ├─ preview_hash 一致（前端必须回传）
  │    └─ plan_hash 一致（防止 payload 被篡改）
  │
  └─ 4. 一次性使用
       └─ 执行后立即删除 token
```

**前端流程**：
```typescript
// 1. 收到预览响应
const response = await api.chatEdit({...});
if (response.status === "need_confirm") {
  const { preview, confirm_token, preview_hash } = response;
  
  // 2. 展示预览给用户
  showPreview(preview);
  
  // 3. 用户确认后，回传 preview_hash
  await api.confirm({
    session_id,
    doc_id,
    confirm_token,
    preview_hash,  // 必须回传
    action: "apply"
  });
}
```

**安全保证**：
- 用户看到的预览 === 实际执行的修改
- Token 无法被复用到其他预览
- Payload 无法被篡改
- 并发修改会被检测并拒绝

### 12.1 权限控制

```python
def check_document_permission(user_id: str, doc_id: str, action: str) -> bool:
    """检查用户对文档的权限"""
    doc = db.get_document(doc_id)
    
    # 文档所有者
    if doc.user_id == user_id:
        return True
    
    # 检查共享权限
    permission = db.get_document_permission(doc_id, user_id)
    if permission:
        if action == "read" and permission.can_read:
            return True
        if action == "edit" and permission.can_edit:
            return True
    
    return False

@app.post("/v1/chat/edit")
async def chat_edit(request: ChatEditRequest, user_id: str = Depends(get_current_user)):
    if not check_document_permission(user_id, request.doc_id, "edit"):
        raise HTTPException(403, "No permission to edit this document")
    
    # ...
```

### 12.2 内容安全

```python
def validate_content_safety(content: str) -> bool:
    """检查内容安全性"""
    # 1. 长度限制
    if len(content) > 50000:
        raise ValidationError("Content too long")
    
    # 2. 敏感词过滤（可选）
    if contains_sensitive_words(content):
        raise ValidationError("Content contains sensitive words")
    
    # 3. XSS 防护
    if contains_xss_patterns(content):
        raise ValidationError("Content contains potential XSS")
    
    return True
```

### 12.3 审计日志

```python
def log_edit_operation(user_id: str, doc_id: str, operation: EditOperation):
    """记录编辑操作到审计日志"""
    audit_log = {
        "timestamp": datetime.utcnow().isoformat(),
        "user_id": user_id,
        "doc_id": doc_id,
        "operation_type": operation.op_type,
        "target_block_id": operation.target_block_id,
        "before_hash": operation.before_hash,
        "after_hash": operation.after_hash,
        "ip_address": request.client.host,
        "user_agent": request.headers.get("user-agent")
    }
    
    # 写入审计日志表或日志文件
    db.insert_audit_log(audit_log)
```

---

## 13. 监控与告警

### 13.1 关键指标

```python
from prometheus_client import Counter, Histogram, Gauge

# 业务指标
edit_requests_total = Counter("edit_requests_total", "Total edit requests", ["status"])
edit_latency = Histogram("edit_latency_seconds", "Edit request latency")
disambiguation_rate = Gauge("disambiguation_rate", "Rate of disambiguation needed")

# 系统指标
db_query_latency = Histogram("db_query_latency_seconds", "Database query latency")
meili_search_latency = Histogram("meili_search_latency_seconds", "Meilisearch latency")
llm_call_latency = Histogram("llm_call_latency_seconds", "LLM call latency")

# 错误指标
validation_failures = Counter("validation_failures_total", "Validation failures")
concurrent_edit_conflicts = Counter("concurrent_edit_conflicts_total", "Concurrent edit conflicts")
```

### 13.2 告警规则

```yaml
# Prometheus 告警规则
groups:
  - name: doc_edit_alerts
    rules:
      - alert: HighDisambiguationRate
        expr: disambiguation_rate > 0.5
        for: 5m
        annotations:
          summary: "定位准确率下降"
          description: "过去 5 分钟内超过 50% 的请求需要用户选择候选"
      
      - alert: HighEditLatency
        expr: histogram_quantile(0.95, edit_latency_seconds) > 10
        for: 5m
        annotations:
          summary: "编辑延迟过高"
          description: "95 分位延迟超过 10 秒"
      
      - alert: FrequentConcurrentConflicts
        expr: rate(concurrent_edit_conflicts_total[5m]) > 0.1
        for: 5m
        annotations:
          summary: "并发冲突频繁"
          description: "过去 5 分钟内并发冲突率超过 10%"
```

---

## 14. 部署架构

### 14.1 推荐架构

```text
┌─────────────┐
│   用户      │
└──────┬──────┘
       │
       ↓
┌─────────────────────────────────────┐
│  Load Balancer (Nginx/ALB)          │
└──────┬──────────────────────────────┘
       │
       ↓
┌─────────────────────────────────────┐
│  API Servers (FastAPI) × 3          │
│  - Gunicorn + Uvicorn workers       │
│  - Auto-scaling based on CPU        │
└──────┬──────────────────────────────┘
       │
       ├──────────────┬──────────────┬──────────────┐
       ↓              ↓              ↓              ↓
┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐
│ Postgres │   │  Redis   │   │Meilisearch│   │  LLM API │
│ (Primary)│   │ (Cache)  │   │  (Search) │   │  (Qwen)  │
└────┬─────┘   └──────────┘   └──────────┘   └──────────┘
     │
     ↓
┌──────────┐
│ Postgres │
│(Replica) │
└──────────┘
```

### 14.2 容量规划

| 组件 | 配置 | 说明 |
|-----|------|------|
| API Server | 4 vCPU, 8GB RAM × 3 | 支持 100 并发请求 |
| Postgres | 8 vCPU, 32GB RAM | 1TB SSD，支持 1000 TPS |
| Redis | 4 vCPU, 16GB RAM | 100GB 内存，支持 10 万 QPS |
| Meilisearch | 8 vCPU, 16GB RAM | 500GB SSD，支持 1000 万文档 |

**扩展策略**：
- API Server：水平扩展，根据 CPU 使用率自动伸缩
- Postgres：读写分离，主从复制
- Redis：主从 + 哨兵模式
- Meilisearch：单实例（暂不支持集群）

---

## 15. MVP 实施路径

### Phase 1：核心功能（2-3 周）

**目标**：验证核心流程

1. **数据模型**（3 天）
   - Postgres 表结构（模式 A：全量复制）
   - 基础 DAO 层

2. **上传与分块**（2 天）
   - 支持 txt/md 格式
   - 按自然段切分
   - 写入数据库

3. **单次编辑流程**（7 天）
   - IntentParser → Retriever（BM25） → Verifier → Planner → Apply
   - 支持 replace 操作
   - evidence_quote 子串校验

4. **导出**（1 天）
   - 按 order_index 拼接
   - 返回 Markdown

5. **基础 API**（2 天）
   - POST /upload
   - POST /chat/edit
   - GET /export

### Phase 2：体验优化（2 周）

**目标**：提升准确性和用户体验

6. **候选选择**（2 天）
   - 定位不确定时返回候选
   - 用户选择后重新调用

7. **预览确认**（3 天）
   - 生成 before/after diff
   - confirm_token 机制
   - POST /chat/confirm

8. **版本管理**（2 天）
   - GET /revisions
   - POST /rollback

9. **并发控制**（2 天）
   - 乐观锁 CAS
   - 冲突重试

10. **多轮上下文**（2 天）
    - chat_messages.meta 存储
    - 支持"刚才那段"

### Phase 3：性能与可观测性（2 周）

**目标**：支持生产环境

11. **混合检索**（3 天）
    - 向量检索（pgvector）
    - RRF 融合

12. **缓存优化**（2 天）
    - Redis 缓存
    - 本地 LRU 缓存

13. **Langfuse 埋点**（2 天）
    - trace/span 追踪
    - 业务指标统计

14. **监控告警**（2 天）
    - Prometheus 指标
    - Grafana 仪表盘

15. **压力测试**（2 天）
    - Locust 压测
    - 性能调优

### Phase 4：高级功能（按需）

16. **批量修改**（3 天）
    - BULK_DISCOVER/PREVIEW/APPLY 节点

17. **Block Version 引用模式**（5 天）
    - 模式 B：parent_version_id
    - 递归查询优化

18. **docx 支持**（3 天）
    - 上传 docx 转 md
    - 导出 md 转 docx

---

## 16. 总结

### 核心优势

1. **性能可扩展**：支持从简单方案（模式 A）平滑升级到高性能方案（模式 B）
2. **查找准确性高**：混合检索（BM25 + 向量 + 重排）+ evidence_quote 位置校验
3. **逻辑完整**：版本化、审计、回滚、并发控制、错误恢复全覆盖
4. **工程化强**：缓存、监控、告警、部署架构完整

### 关键设计决策

| 决策点 | 选择 | 理由 |
|-------|------|------|
| Block 身份 | 稳定 block_id + block_versions | 可追溯，支持引用父版本优化 |
| 存储模式 | 模式 A（MVP）→ 模式 B（优化） | 渐进式优化，降低初期复杂度 |
| 检索策略 | BM25（MVP）→ 混合检索（优化） | 平衡准确性与实现成本 |
| 并发控制 | 乐观锁 CAS | 性能好，适合低冲突场景 |
| 缓存架构 | 本地 + Redis 两级 | 降低延迟，支持分布式 |

### 预期效果

- **准确性**：定位准确率 > 85%（混合检索 + 重排）
- **性能**：单次编辑延迟 < 3 秒（P95）
- **并发**：支持 100 并发编辑请求
- **可用性**：99.9% SLA

### 后续优化方向

1. **自定义重排模型**：基于用户反馈训练
2. **增量 revision**：大文档性能优化
3. **协同编辑**：WebSocket 实时同步
4. **AI 建议**：主动发现文档问题并建议修改
